{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f547078",
   "metadata": {},
   "source": [
    "# PIPLELINE FOR DATA WAREHOUSING AND DASHBOARDING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146f8e9e",
   "metadata": {},
   "source": [
    "## Connection to Data Source\n",
    "This funstion connects to the OLTP database named Airline in MySQL dbms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "961cc666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "\n",
    "def connect_to_data_source():\n",
    "    connection_params = {\n",
    "        'host': 'localhost',\n",
    "        'database': 'airline',\n",
    "        'user': 'root',\n",
    "        'password': 'hina1234'\n",
    "    }\n",
    "    \n",
    "    connection = mysql.connector.connect(\n",
    "        host=connection_params['host'],\n",
    "        user=connection_params['user'],\n",
    "        password=connection_params['password'],\n",
    "        database=connection_params['database']\n",
    "    )\n",
    "    \n",
    "    return connection\n",
    "\n",
    "connection=connect_to_data_source()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db3024a",
   "metadata": {},
   "source": [
    "## Data ingestion\n",
    "This function extract relevant attributes from the OLTP database that are to be used in Star Schema creation.\n",
    "\n",
    "These attrbutes are then stored in a satging area which is a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "431765db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "\n",
    "def ingest_data(connection):\n",
    "    # Define the query\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        A.Aircraft_Type, A.Manufacturer, A.Capacity,\n",
    "        AMH.Maintenance_Date, \n",
    "        R.Distance, \n",
    "        T.Amount, \n",
    "        CF.Cancellation_Reason, CF.Cancellation_date, CF.Cancellation_time,\n",
    "        RF.Reimbursement_fee, \n",
    "        DF.Airport_Name as DepartureAirport, AF.Airport_Name as ArrivalAirport, F.FlightDuration, F.TicketPrice, F.DepartureDate, F.DepartureTime, F.ArrivalDate, F.ArrivalTime,F.Over_Booked,\n",
    "        DF.City as Dep_City, DF.Country as Dep_Country, DF.Latitude as Dep_Latitude, DF.Longitude as Dep_Longitude,\n",
    "        AF.City as Arrival_City, AF.Country as Arrival_Country, AF.Latitude as Arrival_Latitude, AF.Longitude as Arrival_Longitude,\n",
    "        CCF.Compensation_Amount\n",
    "    FROM Cancelled_Flights CF\n",
    "    LEFT JOIN Flight F ON CF.FlightID=F.FlightID\n",
    "    LEFT JOIN Aircraft A ON F.AircraftID=A.AircraftID\n",
    "    LEFT JOIN aircraft_maintenance_history AMH ON A.AircraftID=AMH.AircraftID\n",
    "    LEFT JOIN Airport DF ON F.DepartureAirportID=DF.AirportID\n",
    "    LEFT JOIN Airport AF ON F.ArrivalAirportID=AF.AirportID\n",
    "    LEFT JOIN Routes R ON DF.AirportID = R.Departure_AirportID AND AF.AirportID = R.Arrival_AirportID\n",
    "    LEFT JOIN Reservation RS ON F.FlightID=RS.FlightID\n",
    "    LEFT JOIN Transaction T ON RS.ReservationID=T.ReservationID\n",
    "    LEFT JOIN Cancelled_Flight_Compensation CCF ON CF.FlightID=CCF.FlightID\n",
    "    LEFT JOIN Rescheduled_Flights RF ON CF.CancellationID=RF.CancellationID;\n",
    "    \"\"\"\n",
    "    # Execute the query and fetch the data\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(query)\n",
    "    data = cursor.fetchall()\n",
    "    \n",
    "    # Get column names\n",
    "    columns = [desc[0] for desc in cursor.description]\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    \n",
    "    # Close the cursor and connection\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    \n",
    "    return df\n",
    "staging_area = ingest_data(connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa814c6",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "This function cleans the data by removing any null values in the dataframe staging area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dd7475f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(staging_area):\n",
    "    # Interpolate numerical columns\n",
    "    cleaned_data = staging_area.interpolate(method='ffill', axis=0)\n",
    "    \n",
    "    # Fill missing values in categorical columns with mode\n",
    "    for column in cleaned_data.select_dtypes(include='object'):\n",
    "        cleaned_data[column] = cleaned_data[column].fillna(cleaned_data[column].mode().iloc[0])\n",
    "    \n",
    "    return cleaned_data\n",
    "\n",
    "staging_area = clean_data(staging_area)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3de896",
   "metadata": {},
   "source": [
    "## Creation of New Attributes\n",
    "These functions create new attributes which are required in the Star Schema. \n",
    "These includes:\n",
    "1. Primary keys for the dimension tables\n",
    "2. Derived Facts\n",
    "3. Extraction of data and time components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "53387d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_new_attributes(staging_area):\n",
    "    \n",
    "    # Define the function to create new attributes\n",
    "    def add_attribute(staging_area, new_att, operation, column1, column2):\n",
    "        if operation == 'add':\n",
    "            staging_area[new_att] = staging_area[column1] + staging_area[column2]\n",
    "        elif operation == 'subtract':\n",
    "            staging_area[new_att] = staging_area[column1] - staging_area[column2]\n",
    "        elif operation == 'multiply':\n",
    "            staging_area[new_att] = staging_area[column1] * staging_area[column2]\n",
    "        elif operation == 'divide':\n",
    "            staging_area[new_att] = staging_area[column1] / staging_area[column2]\n",
    "        elif operation == 'time_difference':\n",
    "            staging_area[new_att] = (staging_area[column1] - staging_area[column2]).dt.components.hours\n",
    "        elif operation == 'date_difference':\n",
    "            staging_area[new_att] = (pd.to_datetime(staging_area[column1]) - pd.to_datetime(staging_area[column2])).dt.days\n",
    "        else:\n",
    "            print(\"Invalid operation. Please choose from 'add', 'subtract', 'multiply', 'divide', 'time_difference', or 'date_difference'.\")\n",
    "        \n",
    "        return staging_area\n",
    "    \n",
    "    # Call the function to create new attributes\n",
    "    staging_area = add_attribute(staging_area, 'Duration_of_Flight', 'time_difference', 'DepartureTime', 'ArrivalTime')\n",
    "    staging_area = add_attribute(staging_area, 'Lead_Time', 'time_difference', 'Cancellation_time', 'DepartureTime')\n",
    "    staging_area = add_attribute(staging_area, 'Cost', 'add', 'Compensation_Amount', 'Reimbursement_fee')\n",
    "    staging_area = add_attribute(staging_area, 'Revenue_Loss', 'subtract', 'Amount', 'Cost')\n",
    "    \n",
    "    return staging_area\n",
    "\n",
    "# Call the function to perform all operations\n",
    "staging_area = create_new_attributes(staging_area)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "96523838",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_primary_keys(df):\n",
    "    df['DateID'] = df.index.map(lambda x: 'D' + str(x + 1))\n",
    "    df['TimeID'] = df.index.map(lambda x: 'T' + str(x + 1))\n",
    "    df['Dep_LocID'] = df.index.map(lambda x: 'DL' + str(x + 1))\n",
    "    df['Arrival_LocID'] = df.index.map(lambda x: 'AL' + str(x + 1))\n",
    "    df['AircraftID'] = df.index.map(lambda x: 'A' + str(x + 1))\n",
    "    df['ReasonID'] = df.index.map(lambda x: 'R' + str(x + 1))\n",
    "    return df\n",
    "\n",
    "staging_area = generate_primary_keys(staging_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a7c04f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date_components(df, prefix, date_column):\n",
    "    df[date_column] = pd.to_datetime(df[date_column])\n",
    "    df[prefix + 'Day'] = df[date_column].dt.day\n",
    "    df[prefix + 'Quarter'] = df[date_column].dt.quarter\n",
    "    df[prefix + 'Month'] = df[date_column].dt.month\n",
    "    df[prefix + 'Week'] = df[date_column].dt.isocalendar().week\n",
    "    df[prefix + 'Year'] = df[date_column].dt.year\n",
    "    return df\n",
    "\n",
    "staging_area = extract_date_components(staging_area, '', 'Cancellation_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ab52be21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_time_components(df, prefix, time_column):\n",
    "    \n",
    "    df[prefix + 'Hour'] = df[time_column].dt.components.hours\n",
    "    df[prefix + 'Minute'] = df[time_column].dt.components.minutes\n",
    "    df[prefix + 'Second'] = df[time_column].dt.components.seconds\n",
    "    return df\n",
    "\n",
    "staging_area = extract_time_components(staging_area, '', 'Cancellation_time')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0ece30",
   "metadata": {},
   "source": [
    "## Creation of Star Schema Tables\n",
    "This function create the Dimension and Fact tables in a new database in MySQL called data warehouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5ec070d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, MetaData, Table, Column, Integer, String, ForeignKey, Date, DECIMAL\n",
    "\n",
    "def create_star_schema_tables(engine, schema_definition):\n",
    "    metadata = MetaData()\n",
    "    for table_name, columns in schema_definition.items():\n",
    "        columns_list = []\n",
    "        for col_name, col_type in columns.items():\n",
    "            column_kwargs = {}\n",
    "            is_foreign_key = False\n",
    "            if 'primary_key=True' in col_type:\n",
    "                column_kwargs['primary_key'] = True\n",
    "                col_type = col_type.replace(', primary_key=True', '')\n",
    "            if 'ForeignKey' in col_type:\n",
    "                foreign_key = col_type.split('ForeignKey(')[1].split(')')[0]\n",
    "                is_foreign_key = True\n",
    "                col_type = col_type.split(', ForeignKey(')[0]\n",
    "            \n",
    "            if col_type.startswith('String'):\n",
    "                length = int(col_type.split('(')[1].split(')')[0])\n",
    "                column = Column(col_name, String(length), **column_kwargs)\n",
    "            elif col_type.startswith('Integer'):\n",
    "                column = Column(col_name, Integer, **column_kwargs)\n",
    "            elif col_type.startswith('Date'):\n",
    "                column = Column(col_name, Date, **column_kwargs)\n",
    "            elif col_type.startswith('Decimal'):\n",
    "                precision, scale = map(int, col_type.split('(')[1].split(')')[0].split(','))\n",
    "                column = Column(col_name, DECIMAL(precision=precision, scale=scale), **column_kwargs)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported column type: {col_type}\")\n",
    "\n",
    "            if is_foreign_key:\n",
    "                column.foreign_keys.add(ForeignKey(foreign_key))\n",
    "\n",
    "            columns_list.append(column)\n",
    "\n",
    "        Table(table_name, metadata, *columns_list)\n",
    "    metadata.create_all(engine)\n",
    "\n",
    "schema_definition = {\n",
    "    'DimDate': {\n",
    "        'DateID': 'String(50), primary_key=True',\n",
    "        'Day': 'Integer',\n",
    "        'Week': 'Integer',\n",
    "        'Month': 'String(50)',\n",
    "        'Quarter': 'Integer',\n",
    "        'Year': 'Integer'\n",
    "    },\n",
    "    'DimTime': {\n",
    "        'TimeID': 'String(50), primary_key=True',\n",
    "        'Hour': 'Integer',\n",
    "        'Minute': 'Integer',\n",
    "        'Second': 'Integer'\n",
    "    },\n",
    "    'DimDep_Location': {\n",
    "        'Dep_LocID': 'String(50), primary_key=True',\n",
    "        'Dep_Country': 'String(50)',\n",
    "        'Dep_City': 'String(50)',\n",
    "        'Dep_Latitude': 'Decimal(10,2)',\n",
    "        'Dep_Longitude': 'Decimal(10,2)'\n",
    "    },\n",
    "    'DimArrival_Location': {\n",
    "        'Arrival_LocID': 'String(50), primary_key=True',\n",
    "        'Arrival_Country': 'String(50)',\n",
    "        'Arrival_City': 'String(50)',\n",
    "        'Arrival_Latitude': 'Decimal(10,2)',\n",
    "        'Arrival_Longitude': 'Decimal(10,2)'\n",
    "    },  \n",
    "    'DimAircraft': {\n",
    "        'AircraftID': 'String(50), primary_key=True',\n",
    "        'Aircraft_Type': 'String(50)',\n",
    "        'Manufacturer': 'String(50)',\n",
    "        'Maintenance_Date': 'Date'\n",
    "    },  \n",
    "    'DimReason': {\n",
    "        'ReasonID': 'String(50), primary_key=True',\n",
    "        'Cancellation_Reason': 'String(50)'\n",
    "    },\n",
    "    'FactCanc_Flight': {\n",
    "        'FactID': 'String(50), primary_key=True',\n",
    "        'DateID': 'String(50), ForeignKey(DimDate.DateID)',\n",
    "        'TimeID': 'String(50), ForeignKey(DimTime.TimeID)',\n",
    "        'Dep_LocID': 'String(50), ForeignKey(DimDep_Location.Dep_LocID)',\n",
    "        'Arrival_LocID': 'String(50), ForeignKey(DimArrival_Location.Arrival_LocID)',\n",
    "        'AircraftID': 'String(50), ForeignKey(DimAircraft.AircraftID)',\n",
    "        'ReasonID': 'String(50), ForeignKey(DimReason.ReasonID)',\n",
    "        'Over_Booked': 'Integer',\n",
    "        'Capacity': 'Integer',\n",
    "        'Distance': 'Integer',\n",
    "        'Amount': 'Integer',\n",
    "        'Lead_Time': 'Integer',\n",
    "        'Duration_of_Flight': 'Integer',\n",
    "        'Revenue_Loss': 'Integer',\n",
    "        'Cost': 'Integer'\n",
    "    }\n",
    "}\n",
    "\n",
    "engine = create_engine('mysql+mysqlconnector://root:hina1234@localhost/data warehouse')\n",
    "create_star_schema_tables(engine, schema_definition)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a83a883",
   "metadata": {},
   "source": [
    "## Mapping of Data to Dimension Tables\n",
    "This function maps data from the staging area to the dimension tables in our data warehouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "36393bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "def map_to_dimtable(staging_area):\n",
    "    engine = create_engine('mysql+mysqlconnector://root:hina1234@localhost/data warehouse')\n",
    "    dimension_mappings = {\n",
    "    'dimdate': ['DateID','Day', 'Week', 'Month', 'Quarter', 'Year'],\n",
    "    'dimtime': [ 'TimeID','Hour', 'Minute', 'Second'],\n",
    "    'dimdep_location': ['Dep_LocID','Dep_Country', 'Dep_City', 'Dep_Latitude', 'Dep_Longitude'],\n",
    "    'dimarrival_location': ['Arrival_LocID','Arrival_Country', 'Arrival_City', 'Arrival_Latitude', 'Arrival_Longitude'],\n",
    "    'dimaircraft':['AircraftID','Aircraft_Type','Manufacturer','Maintenance_Date'],\n",
    "    'dimreason':['ReasonID','Cancellation_Reason']\n",
    "    }\n",
    "    with engine.connect() as connection:\n",
    "        for table_name, columns in dimension_mappings.items():\n",
    "            dimension_data = staging_area[columns].copy()\n",
    "            dimension_data.to_sql(table_name, connection, if_exists='replace', index=False)\n",
    "            \n",
    "map_to_dimtable(staging_area)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7381f91b",
   "metadata": {},
   "source": [
    "## Mapping of Data to Fact Table\n",
    "This function maps data from the staging area to the fact table in our data warehouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "22e5a5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "def map_to_facttable(staging_area):\n",
    "    engine = create_engine('mysql+mysqlconnector://root:hina1234@localhost/data warehouse')\n",
    "    dimension_mappings = {\n",
    "    'dimdate': ['DateID'],\n",
    "    'dimtime': ['TimeID'],\n",
    "    'dimdep_location': ['Dep_LocID'],\n",
    "    'dimarrival_location': ['Arrival_LocID'],\n",
    "    'dimaircraft': ['AircraftID'],\n",
    "    'dimreason': ['ReasonID'],\n",
    "    \n",
    "    }\n",
    "    fact_mappings = {\n",
    "    'factcanc_flight': ['DateID', 'TimeID', 'Dep_LocID', 'Arrival_LocID', 'AircraftID', 'ReasonID','Over_Booked', 'Capacity', 'Distance', 'Amount', 'Lead_Time', 'Duration_of_Flight', 'Revenue_Loss', 'Cost']\n",
    "    }\n",
    "    with engine.connect() as connection:\n",
    "        for table_name, columns in fact_mappings.items():\n",
    "            fact_data = staging_area[columns].copy()\n",
    "            fact_data['FactID'] = range(1, len(fact_data) + 1)\n",
    "            # Join with dimension tables to get foreign keys\n",
    "            for dim_table, dim_columns in dimension_mappings.items():\n",
    "                for dim_col in dim_columns:\n",
    "                    if dim_col in fact_data.columns:\n",
    "                        dim_data = pd.read_sql(f\"SELECT {dim_col} FROM {dim_table}\", connection)\n",
    "                        fact_data = fact_data.merge(dim_data, on=dim_col, how='left')\n",
    "            \n",
    "            # Writing data to SQL, including primary key column\n",
    "            \n",
    "            fact_data.to_sql(table_name, connection, if_exists='replace', index=False)\n",
    "\n",
    "map_to_facttable(staging_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7350e9f",
   "metadata": {},
   "source": [
    "## Execution of Dimensional Queiries:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07371869",
   "metadata": {},
   "source": [
    "### The following code executes these Dimensional Queries.\n",
    "1. WHAT IS THE AVERAGE NO. OF FLIGHTS CANCELLED IN CANADA BECUASE OF CREW UNAVAILABILITY?\n",
    "2. WHICH AIRPLANE'S FLIGHTS GETS CANCELLED THE MOST?\n",
    "3. WHAT IS THE TOTAL REVENUE_LOSS IN 2023?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "834667b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensional Query 1: Average Cancelled Flights in Canada:\n",
      "   average_cancelled_flights\n",
      "0                      113.0\n",
      "\n",
      "Dimensional Query 2: Aircraft with highest no. of cancelled flights:\n",
      "   aircraft_type  cancelled_flights\n",
      "0  Regional Jets              13359\n",
      "\n",
      "Dimensional Query 3: Total Revenue loss in 2023:\n",
      "   sum(f.revenue_loss)\n",
      "0         3.916041e+09\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "def execute_dimensional_queries():\n",
    "    queries = {\n",
    "        \"Dimensional Query 1: Average Cancelled Flights in Canada\": \"\"\"\n",
    "            SELECT AVG(cancelled_flights) AS average_cancelled_flights\n",
    "            FROM (\n",
    "                SELECT COUNT(*) AS cancelled_flights\n",
    "                FROM factcanc_flight f\n",
    "                JOIN DimDep_Location as DL on f.Dep_LocID=DL.Dep_LocID\n",
    "                JOIN DimReason as R on f.ReasonID=R.ReasonID\n",
    "                WHERE Dep_Country = 'Canada'\n",
    "                  AND cancellation_reason = 'Crew Unavailability'\n",
    "                GROUP BY DATE(DateID)\n",
    "            ) AS daily_cancelled_flights;\n",
    "        \"\"\",\n",
    "        \"Dimensional Query 2: Aircraft with highest no. of cancelled flights\":\"\"\"\n",
    "        select a.aircraft_type, COUNT(FactID) as cancelled_flights from DimAircraft a\n",
    "        join factcanc_flight f on a.AircraftID=f.AircraftID\n",
    "        GROUP BY a.aircraft_type\n",
    "        ORDER BY cancelled_flights desc limit 1;\n",
    "        \"\"\",\n",
    "        \"Dimensional Query 3: Total Revenue loss in 2023\": \"\"\"\n",
    "        SELECT sum(f.revenue_loss) from factcanc_flight f \n",
    "        join DimDate d on f.DateID=d.DateID\n",
    "        where d.year=2023\n",
    "        \"\"\"\n",
    "    }\n",
    "    \n",
    "    engine = create_engine('mysql+mysqlconnector://root:hina1234@localhost/data warehouse')\n",
    "    results = {}\n",
    "    for query_name, query in queries.items():\n",
    "        results[query_name] = pd.read_sql(query, engine)\n",
    "        \n",
    "    # Print the results\n",
    "    for query_name, result in results.items():\n",
    "        print(f\"{query_name}:\")\n",
    "        print(f\"{result}\\n\")\n",
    "\n",
    "execute_dimensional_queries()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7bc171",
   "metadata": {},
   "source": [
    "## Fact Table snapshot\n",
    "This function creates a dataframe of Fact table snapshot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c223f196",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def extract_fact_table_snapshot():\n",
    "    fact_table = 'factcanc_flight'\n",
    "    dimension_tables = ['dimdate', 'dimtime', 'dimdep_location', 'dimarrival_location', 'dimaircraft', 'dimreason']\n",
    "    \n",
    "    snapshot_query = f\"\"\"\n",
    "        SELECT f.FactID,f.Capacity,f.Distance,f.Amount,f.Lead_Time,f.Duration_of_Flight,f.Revenue_Loss,f.Cost,f.Over_Booked,\n",
    "               d1.Day, d1.Week, d1.Month, d1.Quarter, d1.Year,\n",
    "               d2.Hour, d2.Minute, d2.Second, \n",
    "               d3.Dep_Country, d3.Dep_City, d3.Dep_Latitude, d3.Dep_Longitude,\n",
    "               d4.Arrival_Country,d4.Arrival_City,d4.Arrival_Latitude,d4.Arrival_Longitude,\n",
    "               d5.Aircraft_Type,d5.Manufacturer,d5.Maintenance_Date,\n",
    "               d6.Cancellation_Reason\n",
    "        FROM {fact_table} f\n",
    "        JOIN dimdate d1 ON f.DateID = d1.DateID\n",
    "        JOIN dimtime d2 ON f.TimeID = d2.TimeID\n",
    "        JOIN dimdep_location d3 ON f.Dep_LocID = d3.Dep_LocID\n",
    "        JOIN dimarrival_location d4 ON f.Arrival_LocID = d4.Arrival_LocID\n",
    "        JOIN dimaircraft d5 ON f.AircraftID = d5.AircraftID\n",
    "        JOIN dimreason d6 ON f.ReasonID = d6.ReasonID\n",
    "    \"\"\"\n",
    "    \n",
    "    engine = create_engine('mysql+mysqlconnector://root:hina1234@localhost/data warehouse')\n",
    "    \n",
    "    snapshot = pd.read_sql(snapshot_query, engine)\n",
    "    \n",
    "    # Adding date of data entry to track percentage change later\n",
    "    def add_date_col(snapshot):\n",
    "        def current_time_hour_minute():\n",
    "            return datetime.now().replace(second=0, microsecond=0)\n",
    "\n",
    "        snapshot['DateTime'] = current_time_hour_minute()\n",
    "        return snapshot\n",
    "\n",
    "    snapshot = add_date_col(snapshot)\n",
    "    \n",
    "    return snapshot\n",
    "\n",
    "# Call the function to extract the fact table snapshot\n",
    "snapshot_ft = extract_fact_table_snapshot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1394e5",
   "metadata": {},
   "source": [
    "## Exporting Fact Table Snapshot to SQL for Dashboarding\n",
    " This snapshot is then exported to MySQL database 'data warehouse' which is then exported to Power BI for dashboarding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7fe02c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_ft(snapshot):\n",
    "    engine = create_engine('mysql+mysqlconnector://root:hina1234@localhost/data warehouse')\n",
    "    snapshot.to_sql('fact_table_snapshot', con=engine, if_exists='replace', index=False)\n",
    "export_ft(snapshot_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27908989",
   "metadata": {},
   "source": [
    "## POWER BI DASHBOARD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea5ae26",
   "metadata": {},
   "source": [
    "The Dynamic Power BI Dashboard is hosted on the web.\n",
    "\n",
    "After that more OLTP data was generated and pipleine was executed to update the dashboard. The percentage change in updates was also recorded in a dashboard. Both of the dashbboards were hosted.\n",
    "\n",
    "[View Dashboard](https://app.powerbi.com/view?r=eyJrIjoiOWY3MTc3ODktMjE4Ny00Zjc3LTgwMWQtN2Q0NWY5ODkzOTNmIiwidCI6ImZlZTNiOTE2LTAxYzEtNDk4Ny1hNjQ2LWUxOTM0MzJiOWVhYSIsImMiOjl9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a13282",
   "metadata": {},
   "source": [
    "## MASTER FUNCTION\n",
    "This function automates everything. When new data is updated in the OLTP database, this fucntion runs and updates data in data warehouse and also export it to power BI so the dashboard updates automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "549d26e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensional Query 1: Average Cancelled Flights in Canada:\n",
      "   average_cancelled_flights\n",
      "0                      113.0\n",
      "\n",
      "Dimensional Query 2: Aircraft with highest no. of cancelled flights:\n",
      "   aircraft_type  cancelled_flights\n",
      "0  Regional Jets              12977\n",
      "\n",
      "Dimensional Query 3: Total Revenue loss in 2023:\n",
      "   sum(f.revenue_loss)\n",
      "0         3.916041e+09\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FactID</th>\n",
       "      <th>Capacity</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Lead_Time</th>\n",
       "      <th>Duration_of_Flight</th>\n",
       "      <th>Revenue_Loss</th>\n",
       "      <th>Cost</th>\n",
       "      <th>Over_Booked</th>\n",
       "      <th>Day</th>\n",
       "      <th>...</th>\n",
       "      <th>Dep_Longitude</th>\n",
       "      <th>Arrival_Country</th>\n",
       "      <th>Arrival_City</th>\n",
       "      <th>Arrival_Latitude</th>\n",
       "      <th>Arrival_Longitude</th>\n",
       "      <th>Aircraft_Type</th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>Maintenance_Date</th>\n",
       "      <th>Cancellation_Reason</th>\n",
       "      <th>DateTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>14214</td>\n",
       "      <td>458052.0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>426034.0</td>\n",
       "      <td>32018</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>-65.85</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Plano</td>\n",
       "      <td>-36.97</td>\n",
       "      <td>-59.19</td>\n",
       "      <td>Commercial Airliner</td>\n",
       "      <td>Airbus</td>\n",
       "      <td>2024-03-30</td>\n",
       "      <td>Crew Unavailability</td>\n",
       "      <td>2024-06-02 14:53:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>14214</td>\n",
       "      <td>275331.0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>243313.0</td>\n",
       "      <td>32018</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>-65.85</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Plano</td>\n",
       "      <td>-36.97</td>\n",
       "      <td>-59.19</td>\n",
       "      <td>Commercial Airliner</td>\n",
       "      <td>Airbus</td>\n",
       "      <td>2024-03-30</td>\n",
       "      <td>Crew Unavailability</td>\n",
       "      <td>2024-06-02 14:53:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>250</td>\n",
       "      <td>14214</td>\n",
       "      <td>458052.0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>426034.0</td>\n",
       "      <td>32018</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>-65.85</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Plano</td>\n",
       "      <td>-36.97</td>\n",
       "      <td>-59.19</td>\n",
       "      <td>Commercial Airliner</td>\n",
       "      <td>Airbus</td>\n",
       "      <td>2024-09-04</td>\n",
       "      <td>Crew Unavailability</td>\n",
       "      <td>2024-06-02 14:53:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>250</td>\n",
       "      <td>14214</td>\n",
       "      <td>275331.0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>243313.0</td>\n",
       "      <td>32018</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>-65.85</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Plano</td>\n",
       "      <td>-36.97</td>\n",
       "      <td>-59.19</td>\n",
       "      <td>Commercial Airliner</td>\n",
       "      <td>Airbus</td>\n",
       "      <td>2024-09-04</td>\n",
       "      <td>Crew Unavailability</td>\n",
       "      <td>2024-06-02 14:53:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>250</td>\n",
       "      <td>14214</td>\n",
       "      <td>458052.0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>426034.0</td>\n",
       "      <td>32018</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>-65.85</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Plano</td>\n",
       "      <td>-36.97</td>\n",
       "      <td>-59.19</td>\n",
       "      <td>Commercial Airliner</td>\n",
       "      <td>Airbus</td>\n",
       "      <td>2023-10-18</td>\n",
       "      <td>Crew Unavailability</td>\n",
       "      <td>2024-06-02 14:53:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28800</th>\n",
       "      <td>28801</td>\n",
       "      <td>500</td>\n",
       "      <td>12383</td>\n",
       "      <td>322222.0</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>293243.0</td>\n",
       "      <td>28979</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>63.79</td>\n",
       "      <td>Mongolia</td>\n",
       "      <td>Miami</td>\n",
       "      <td>20.70</td>\n",
       "      <td>102.60</td>\n",
       "      <td>Commercial Airliner</td>\n",
       "      <td>Airbus</td>\n",
       "      <td>2024-06-04</td>\n",
       "      <td>Weather Conditions (departure location)</td>\n",
       "      <td>2024-06-02 14:53:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28801</th>\n",
       "      <td>28802</td>\n",
       "      <td>500</td>\n",
       "      <td>12383</td>\n",
       "      <td>322222.0</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>293243.0</td>\n",
       "      <td>28979</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>63.79</td>\n",
       "      <td>Mongolia</td>\n",
       "      <td>Miami</td>\n",
       "      <td>20.70</td>\n",
       "      <td>102.60</td>\n",
       "      <td>Commercial Airliner</td>\n",
       "      <td>Airbus</td>\n",
       "      <td>2024-02-24</td>\n",
       "      <td>Weather Conditions (departure location)</td>\n",
       "      <td>2024-06-02 14:53:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28802</th>\n",
       "      <td>28803</td>\n",
       "      <td>500</td>\n",
       "      <td>12383</td>\n",
       "      <td>322222.0</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>293243.0</td>\n",
       "      <td>28979</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>63.79</td>\n",
       "      <td>Mongolia</td>\n",
       "      <td>Miami</td>\n",
       "      <td>20.70</td>\n",
       "      <td>102.60</td>\n",
       "      <td>Commercial Airliner</td>\n",
       "      <td>Airbus</td>\n",
       "      <td>2023-10-26</td>\n",
       "      <td>Weather Conditions (departure location)</td>\n",
       "      <td>2024-06-02 14:53:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28803</th>\n",
       "      <td>28804</td>\n",
       "      <td>500</td>\n",
       "      <td>12383</td>\n",
       "      <td>322222.0</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>293243.0</td>\n",
       "      <td>28979</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>63.79</td>\n",
       "      <td>Mongolia</td>\n",
       "      <td>Miami</td>\n",
       "      <td>20.70</td>\n",
       "      <td>102.60</td>\n",
       "      <td>Commercial Airliner</td>\n",
       "      <td>Airbus</td>\n",
       "      <td>2023-10-11</td>\n",
       "      <td>Weather Conditions (departure location)</td>\n",
       "      <td>2024-06-02 14:53:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28804</th>\n",
       "      <td>28805</td>\n",
       "      <td>500</td>\n",
       "      <td>12383</td>\n",
       "      <td>322222.0</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>293243.0</td>\n",
       "      <td>28979</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>63.79</td>\n",
       "      <td>Mongolia</td>\n",
       "      <td>Miami</td>\n",
       "      <td>20.70</td>\n",
       "      <td>102.60</td>\n",
       "      <td>Commercial Airliner</td>\n",
       "      <td>Airbus</td>\n",
       "      <td>2024-01-30</td>\n",
       "      <td>Weather Conditions (departure location)</td>\n",
       "      <td>2024-06-02 14:53:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28805 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FactID  Capacity  Distance    Amount  Lead_Time  Duration_of_Flight  \\\n",
       "0           1       250     14214  458052.0          2                  14   \n",
       "1           2       250     14214  275331.0          2                  14   \n",
       "2           3       250     14214  458052.0          2                  14   \n",
       "3           4       250     14214  275331.0          2                  14   \n",
       "4           5       250     14214  458052.0          2                  14   \n",
       "...       ...       ...       ...       ...        ...                 ...   \n",
       "28800   28801       500     12383  322222.0         10                  20   \n",
       "28801   28802       500     12383  322222.0         10                  20   \n",
       "28802   28803       500     12383  322222.0         10                  20   \n",
       "28803   28804       500     12383  322222.0         10                  20   \n",
       "28804   28805       500     12383  322222.0         10                  20   \n",
       "\n",
       "       Revenue_Loss   Cost  Over_Booked  Day  ...  Dep_Longitude  \\\n",
       "0          426034.0  32018            1    6  ...         -65.85   \n",
       "1          243313.0  32018            1    6  ...         -65.85   \n",
       "2          426034.0  32018            1    6  ...         -65.85   \n",
       "3          243313.0  32018            1    6  ...         -65.85   \n",
       "4          426034.0  32018            1    6  ...         -65.85   \n",
       "...             ...    ...          ...  ...  ...            ...   \n",
       "28800      293243.0  28979            1   17  ...          63.79   \n",
       "28801      293243.0  28979            1   17  ...          63.79   \n",
       "28802      293243.0  28979            1   17  ...          63.79   \n",
       "28803      293243.0  28979            1   17  ...          63.79   \n",
       "28804      293243.0  28979            1   17  ...          63.79   \n",
       "\n",
       "      Arrival_Country  Arrival_City  Arrival_Latitude  Arrival_Longitude  \\\n",
       "0              Canada         Plano            -36.97             -59.19   \n",
       "1              Canada         Plano            -36.97             -59.19   \n",
       "2              Canada         Plano            -36.97             -59.19   \n",
       "3              Canada         Plano            -36.97             -59.19   \n",
       "4              Canada         Plano            -36.97             -59.19   \n",
       "...               ...           ...               ...                ...   \n",
       "28800        Mongolia         Miami             20.70             102.60   \n",
       "28801        Mongolia         Miami             20.70             102.60   \n",
       "28802        Mongolia         Miami             20.70             102.60   \n",
       "28803        Mongolia         Miami             20.70             102.60   \n",
       "28804        Mongolia         Miami             20.70             102.60   \n",
       "\n",
       "             Aircraft_Type  Manufacturer Maintenance_Date  \\\n",
       "0      Commercial Airliner        Airbus       2024-03-30   \n",
       "1      Commercial Airliner        Airbus       2024-03-30   \n",
       "2      Commercial Airliner        Airbus       2024-09-04   \n",
       "3      Commercial Airliner        Airbus       2024-09-04   \n",
       "4      Commercial Airliner        Airbus       2023-10-18   \n",
       "...                    ...           ...              ...   \n",
       "28800  Commercial Airliner        Airbus       2024-06-04   \n",
       "28801  Commercial Airliner        Airbus       2024-02-24   \n",
       "28802  Commercial Airliner        Airbus       2023-10-26   \n",
       "28803  Commercial Airliner        Airbus       2023-10-11   \n",
       "28804  Commercial Airliner        Airbus       2024-01-30   \n",
       "\n",
       "                           Cancellation_Reason            DateTime  \n",
       "0                          Crew Unavailability 2024-06-02 14:53:00  \n",
       "1                          Crew Unavailability 2024-06-02 14:53:00  \n",
       "2                          Crew Unavailability 2024-06-02 14:53:00  \n",
       "3                          Crew Unavailability 2024-06-02 14:53:00  \n",
       "4                          Crew Unavailability 2024-06-02 14:53:00  \n",
       "...                                        ...                 ...  \n",
       "28800  Weather Conditions (departure location) 2024-06-02 14:53:00  \n",
       "28801  Weather Conditions (departure location) 2024-06-02 14:53:00  \n",
       "28802  Weather Conditions (departure location) 2024-06-02 14:53:00  \n",
       "28803  Weather Conditions (departure location) 2024-06-02 14:53:00  \n",
       "28804  Weather Conditions (departure location) 2024-06-02 14:53:00  \n",
       "\n",
       "[28805 rows x 30 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Master_Controller():\n",
    "    connection=connect_to_data_source()\n",
    "    staging_area = ingest_data(connection)\n",
    "    staging_area = clean_data(staging_area)\n",
    "    staging_area = create_new_attributes(staging_area)\n",
    "    staging_area = generate_primary_keys(staging_area)\n",
    "    staging_area = extract_date_components(staging_area, '', 'Cancellation_date')\n",
    "    staging_area = extract_time_components(staging_area, '', 'Cancellation_time')\n",
    "    map_to_dimtable(staging_area)\n",
    "    map_to_facttable(staging_area)\n",
    "    execute_dimensional_queries()\n",
    "    snapshot_ft = extract_fact_table_snapshot()\n",
    "    export_ft(snapshot_ft)\n",
    "    \n",
    "Master_Controller()\n",
    "snapshot_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a0c4a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
